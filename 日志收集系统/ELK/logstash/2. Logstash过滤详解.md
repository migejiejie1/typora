**Logstash过滤详解**

搭建ELK时，在Logstash花费了很多的时间，最后也算是摸得个一知半解，话不多说，开始搬砖，
安装不多说，还没搭建的点击→传送门
编辑配置文件

```elm
# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.
input {
		#文件的方式收集日志
        file{
                path => ["xx/xxx.log"]
        }
        #tcp方式收集日志
        tcp{
			port => "5044"
			#自己取的类型
			type => "log4j2"
		}
		#filebeat的方式
		beats{
			port => "5044"
		}
       
}

filter {

   grok{
        match => {
               "message" => "\{\"%{WORD}\":\"\[%{LOGLEVEL:level}\s\]\s%{YEAR:year}-%{MONTHNUM:mouth}-%{MONTHDAY:day} %{HOUR:hour}:?%{MINUTE:minute}(?::?%{SECOND:second})\s%{JAVACLASS:project}\s%{JAVACLASS:class}\(%{JAVAFILE:file}(?::%{NUMBER:line})?\)\s-\[%{UUID:traceId}\]\s-\s(?<msg>.+)\}"
        }
        add_tag => ["myLog"]
    }

         #将massage字段转成json
    json {
           source => "message"
         }
    date {
        match => ["time", "yyyy-MM-dd HH:mm:ss.SSS"]
        remove_field => ["time"]
    }
}
filter{
        if "_grokparsefailure" in [tags]{
        drop{}
}
}

  output {
  # if "traceId" in [message]{
        elasticsearch {
                hosts => ["192.168.1.185:9200"]
                index => "application-%{+YYYY.MM.dd}"
        }
   #}


```

注意
三种input，选一种即可，当然你非要用两种也ok,注意改一下端口就行，file和beat没啥说的，beat我在搭建ELK介绍过了，然后就是tcp方式，拿log4j2举栗子，在log4j2.xml文件中的appender添加一个socket节点就行，亲测可行。
out输出到elasticsearch,可以添加if,else进行删选，logstash的if,else,找了一个https://windcoder.com/logstash6peizhiyufazhongdetiaojianpanduan
重点来了，过滤：
你可以使用if,else语法实现简单地过滤，但我们更多的时候需要用到Logstash的grok过滤插件
正如上面所见，grok的基本语法是这样的

```elm
%{YEAR:year}
```

YEAR:标识匹配年份的字符串
year:将匹配到的字符串存储到year这个变量中，在其他地方你可以直接用这个变量，在kibnan里面也会看见
就相当于他已经把规则给你封装好了，你直接用就行，大概有这么多规则：
https://www.missshi.cn/api/view/blog/5ac6dea622890914df000001
然而内置的不一定满足我们的需求，这时需要我们自己写正则

```elm
(?<name>pattern)
```

name:和上面的year一样，存储匹配到的字段，在其他地方可以直接使用
pattern:自己写的正则表达式。
然后规则就这样，两个可以结合起来一起使用，接下来就写吧，先给个测试的网址http://grokdebug.herokuapp.com/
可以测试你写的正则，举个栗子，这样子的log4j2日志：

```elm
{"log":"[INFO ] 2019-09-16 01:01:06,167 com.byb.provider1.controller.ProviderController com.byb.provider1.controller.ProviderController.test1(ProviderController.java:33) -[b29c258c-0c61-406c-b788-f1496c406924] - uri=test1,我是服务提供者一。欢迎光临。\r\n","stream":"stdout","time":"2019-09-16T01:01:06.172065638Z"}

{"log":"[INFO ] 2019-09-23 03:30:06,607 com.netflix.discovery.DiscoveryClient com.netflix.discovery.DiscoveryClient.unregister(DiscoveryClient.java:942) -[] - DiscoveryClient_TS-PROVIDER1/7cf064f721ba:TS-PROVIDER1:9001 - deregister  status: 200\r\n","stream":"stdout","time":"2019-09-23T03:30:06.610942209Z"}
```

两条日志最主要的区别就是一个有UUID,而一个没有，那我就匹配有UUID的就可以实现过滤，

```elm
\{\"%{WORD}\":\"\[%{LOGLEVEL:level}\s\]\s%{YEAR:year}-%{MONTHNUM:mouth}-%{MONTHDAY:day} %{HOUR:hour}:?%{MINUTE:minute}(?::?%{SECOND:second})\s%{JAVACLASS:project}\s%{JAVACLASS:class}\(%{JAVAFILE:file}(?::%{NUMBER:line})?\)\s-\[%{UUID:traceId}\]\s-\s(?<message>.+)\}
```

这是过滤规则，正则就应该不用我介绍了吧，主要是理解他所规定的格式，聪明的你应该一看就明白，我这么笨都研究出来了，在那个grok语法调试网站你可以很清楚的看见自己所匹配的内容，建议从前往后一个挨个字符串匹配，匹配成功一个，下面json便会多一条数据，这样不会乱。
这里主要用到了内置的java的规则
https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/java
这里面是官方的java内置匹配规则，还有其他语法的，需要的自己去看。
授人以鱼，不如授人以渔。