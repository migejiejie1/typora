使用elkf做日志分析，把收集到的日志通过kafka进行同步，然后使用logstash进行写入到ElasticSearch中，但是在filebeat收集的时候是针对目录进行收集的，所以无法在filebeat进行筛选采集，那就需要在logstash中筛选了，下面就说一下如何在logstash中进行筛选。我的采集是kubernetes中所有的应用程序的日志，这里说的是java程序的日志筛选。看一下我不过滤的日志内容:

![image-20230420100621254](C:\Users\11650\Documents\typora\Image\image-20230420100621254.png)

这里主要的内容有时间戳，字段 @timestamp ，项目名字，字段kubernetes.container.name，日志内容，字段message，下面针对需求的字段进行筛选，我这里是把不需要的删除掉。看我的logstash的配置文件

```elm
input {
  kafka {
    bootstrap_servers =>"10.16.30.1:9092"
    client_id =>"logstash01"
    topics =>["test"]
    group_id =>"logstash"
    decorate_events => true
    codec =>"json" 
  }
}

filter {
  mutate { #删除的字段
  	remove_field => ["_id"]
    remove_field => ["_soure"]
    remove_field => ["_type"]
    remove_field => ["_index"]
    remove_field => ["host"]
    remove_field => ["agent"]
    remove_field => ["ecs"]
    remove_field => ["tags"]
    remove_field => ["fields"]
    remove_field => ["@version"]
    remove_field => ["log"]
    remove_field => ["kubernetes"]
    remove_field => ["input"]
  }
  mutate { #删除的字段，另一种写法
	remove_field => [ "Disabled", "Memo" ]
  }  
  mutate { #添加一个删除的字段
    add_field => {"kubernetes.container.name" => "kubernetes.container.name"}
  } 
}

output {
  elasticsearch {
    hosts => ["http://10.16.30.2:9200"]
    index => "test-%{+YYYY.MM.dd]}"
  }
}
```

因为kubernetes字段中包含了项目名称，如果一个一个的删除，删除不了，所以这里删除了kubernetes中的所有字段，然后把项目名称的字段在添加上，这样就能保留项目字段的内容了。运行一下看看Elasticsearch中写了哪些字段。

![image-20230420102838383](C:\Users\11650\Documents\typora\Image\image-20230420102838383.png)

采集的内容和过滤的一样，这里有几个没有过滤，分别是字段 id，index，_score, type没有过滤，不过滤的原因是过滤不掉，这些是系统自带的，后期如果有好的方法，在继续补充。

总结一下: 这里删除字段的时候必须删除一级字段，例如: 字段kubernetes.container.name，如果我删除字段kubernetes.container.name，在logstash中就不能实现，只能删除kubernetes，会把kubernetes下的所有字段删除，然后在添加自己需要的字段。

