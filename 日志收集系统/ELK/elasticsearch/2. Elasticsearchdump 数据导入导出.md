**Elasticsearchdump 数据导入/导出**

**一、安装过程**

[Elasticsearchdump 仓库地址，详细使用情况](https://github.com/taskrabbit/elasticsearch-dump)

当前工具主要是用来对`ES`中的数据进行数据导入/导出，以及对数据迁移相关，使用`elasticdump`工具需要使用到`npm`，所以需要安装相关的依赖
目前使用到的`ES`版本是`7.x`

**安装NODE**

[NODE和NPM安装链接详细文档](https://www.cnblogs.com/chenhaoyu/p/10237505.html)

安装命令如下：

```
$ wget https://nodejs.org/dist/v10.15.0/node-v10.15.0-linux-x64.tar.xz
$ tar -xf node-v10.15.0-linux-x64.tar.xz
#配置相关的环境变量
$ vim /etc/profile
> PATH=$PATH:/software/node-v10.15.0-linux-x64/bin
$ source /etc/profile
```

**通过npm安装elasticdump**

```
# 本地安装和全局安装的区别在于它是否自动给你设置环境变量，其他的没有区别
# 本地安装
$ npm install elasticdump
$ ./bin/elasticdump

# 全局安装
$ npm install elasticdump -g
$ elasticdump
```

**注：当前工具的安装，我目前是安装在ES集群本地的，当然可以安装在其他节点，只要网络能够被访问，但是因为在本地，所以走本地网卡，速度比较快！**



**二、使用Elasticdump对数据导出**

**ES中将数据导出为本地JSON文件**

```
#格式：elasticdump --input {protocol}://{host}:{port}/{index} --output ./test_index.json
#例子：将ES中的test_index 中的索引导出
#导出当前索引的mapping结构
$ elasticdump --input http://192.168.56.104:9200/test_index --output ./test_index_mapping.json --type=mapping
#导出当前索引下的所有真实数据
$ elasticdump --input http://192.168.56.104:9200/test_index --output ./test_index.json --type=data
```

> 上面导出的两个文件都是在导入到`ES`中所需要的，一个是`mapping`文件，另外一个是`数据`，当然`mapping`也可以自己手动建立

**错误：**在安装完成之后，进行首次使用过程中出现错误，错误主要是`CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory`，出现当前错误

**解决**：试过多种方式，但是最终了能够使程序完整跑出来是因为将内存参数调大

```
$ export NODE_OPTIONS="--max-old-space-size=8192"
```

上面内容设置完成之后，还需要注意，在使用过程中需要注意，`limit（默认值100）`参数和`scrollTime（默认值10m）`，这两个参数都有默认值，

> `limit:`代表的是每次通过请求从ES中请求的数量，之前我将该参数设置为1000，但是出现了内存溢出，默认值就好
>
> `scrollTime:`当前参数代表的是以当前数据生成一个类似镜像的东西，然后通过这个镜像去查询，如果是后面有新的数据进来是不会被纳入的，默认值是10m(分钟)，也就是说，如果数据比较多，导出可能耗时比较久，那么可以将当前参数设置大一些，满足能够将数据导出完

**如何修改参数：**

> - `/root/node-v10.15.0-linux-x64/bin`在安装目录下，找到`elasticdump`脚本文件中，找到对应的参数进行修改
> - 通过直接命令跟参数的形式进行修改，如：`elasticdump --limit=200 --input http://192.168.56.104/test_index --output ./test_index`

![image-20230418175326953](C:\Users\11650\Documents\typora\Image\image-20230418175326953.png)



**三、本地JSON文件导入数据到ES中**

通过上面导出，已经导出了两个文件，一个是`数据`文件，一个是`mapping`文件，进行数据导入：

> 数据导入需要进行检查：
>
> - 在需要导入的`ES`创建索引，并且保持索引和type和`mapping`文件中的一致
> - 是否存在`mapping.json`，这个取决于你是否导出，没倒出也可以自己手动建立，建立过程这里不细说
> - 是否存在相同索引（是否为同一ES中）：存在需要修改导出的`mapping.json`中的索引信息，不存在可以直接导入；

**数据导入：**

```
# 创建索引
$ curl -XPUT http:192.168.56.104:9200/test_index
#因为导入的是mapping，所以设置type为mapping
$ elasticdump --input ./test_index_mapping.json --output http://192.168.56.105:9200/ --type=mapping
#因为导入的是data（真实数据）所以设置type为data
$ elasticdump --input ./test_index.json --output http://192.168.56.105:9200/ --type=data
```

![image-20230418175655970](C:\Users\11650\Documents\typora\Image\image-20230418175655971.png)

![image-20230418175729631](C:\Users\11650\Documents\typora\Image\image-20230418175729631.png)

![image-20230418175803833](C:\Users\11650\Documents\typora\Image\image-20230418175803833.png)

如上图所示，为导入过程

导入导出具体参数要看数据量决定，并且要看单条数据大小决定参数的调整



**四、使用Elasticdump官方的Docker镜像进行数据导入/导出**

在使用前，需要提前安装`Docker`环境，这里不进行细说

```
# 镜像下载
$ docker pull taskrabbit/elasticsearch-dump
# 下面还是例子：通过镜像导出数据到本地
# 创建一个文件夹用于保存导出数据
$ mkdir -p /root/data
# 下面需要对路径进行映射并执行命令（导出mapping）
$ docker run --rm -ti -v /data:/tmp taskrabbit/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=/tmp/my_index_mapping.json \
  --type=mapping
# 导出（data）
$ docker run --rm -ti -v /root/data:/tmp taskrabbit/elasticsearch-dump \
  --input=http://192.168.56.104:9200/test_index \
  --output=/tmp/elasticdump_export.json \
  --type=data
  -----------------------------------------------------------------------------
# 以下内容为ES -> ES的数据迁移例子
$ docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
$ docker run --rm -ti taskrabbit/elasticsearch-dump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data
```

**注：上面的这些导入导出都是最基本的使用，当然还有很多高级用法，参考下面所列出来的命令进行尝试或者直接访问Github官网，查看更加详细的说明，这里只作为记录！**



**Github仓库中的详细格式参考：**

```
# Copy an index from production to staging with analyzer and mapping:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=analyzer
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=http://staging.es.com:9200/my_index \
  --type=data

# Backup index data to a file:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index_mapping.json \
  --type=mapping
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index.json \
  --type=data

# Backup and index to a gzip using stdout:
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=$ \
  | gzip > /data/my_index.json.gz

# Backup the results of a query to a file
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=query.json \
  --searchBody='{"query":{"term":{"username": "admin"}}}'

# Copy a single shard data:
elasticdump \
  --input=http://es.com:9200/api \
  --output=http://es.com:9200/api2 \
  --params='{"preference" : "_shards:0"}'

# Backup aliases to a file
elasticdump \
  --input=http://es.com:9200/index-name/alias-filter \
  --output=alias.json \
  --type=alias

# Import aliases into ES
elasticdump \
  --input=./alias.json \
  --output=http://es.com:9200 \
  --type=alias

# Backup templates to a file
elasticdump \
  --input=http://es.com:9200/template-filter \
  --output=templates.json \
  --type=template

# Import templates into ES
elasticdump \
  --input=./templates.json \
  --output=http://es.com:9200 \
  --type=template

# Split files into multiple parts
elasticdump \
  --input=http://production.es.com:9200/my_index \
  --output=/data/my_index.json \
  --fileSize=10mb

# Import data from S3 into ES (using s3urls)
elasticdump \
  --s3AccessKeyId "${access_key_id}" \
  --s3SecretAccessKey "${access_key_secret}" \
  --input "s3://${bucket_name}/${file_name}.json" \
  --output=http://production.es.com:9200/my_index

# Export ES data to S3 (using s3urls)
elasticdump \
  --s3AccessKeyId "${access_key_id}" \
  --s3SecretAccessKey "${access_key_secret}" \
  --input=http://production.es.com:9200/my_index \
  --output "s3://${bucket_name}/${file_name}.json"
```